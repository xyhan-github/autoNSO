# autoNSO
Naive implementations of common non-smooth optimization (NSO) methods using PyTorch auto-differentiation as the sub-gradient oracle for the purposes of academic exploration and benchmarking. Project is maintained by X.Y. Han, Cornell University ORIE.

If used for academic purposes, please cite as:

X.Y. Han, Naive Implementations of Common NSO Methods with Auto-differentiation, (2019), GitHub repository, https://github.com/charlespwd/project-title
